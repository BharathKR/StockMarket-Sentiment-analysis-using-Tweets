{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-added-on-dec25/json_train_senti25.csv\n",
      "/kaggle/input/data-added-on-dec25/test_data_merged_25.csv\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/json_data_final.csv\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/train_data-1573118738755.json\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/test_data.json\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/test_factors.csv\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/train_factors-1573207730757.csv\n",
      "/kaggle/input/stock-prediction-using-sentiment-analysis/jsonWsenti2.csv\n",
      "/kaggle/input/test-data-final/test_data_merged.csv\n",
      "/kaggle/input/test-data-finallll/test_data_merged_32.csv\n",
      "/kaggle/input/test-data-with-weekday/test_data_merged_67.csv\n",
      "/kaggle/input/train-senti-updated-and-test-data-two-files-merged/json_train_senti69.csv\n",
      "/kaggle/input/train-senti-updated-and-test-data-two-files-merged/train_merged.csv\n",
      "/kaggle/input/finaaaaaal/test_data_merged_19.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "* Loaded the \"cleaned,text classifeid Json file\" and \"factors.csv\" for train and test\n",
    "* Merged the Json and factors file\n",
    "* Built a basic model with all features from merged file, found that the model built had high variance\n",
    "* Dropped relatively un-important features by input form Decision Tree and Random Forest outputs\n",
    "* Experimented with binning on SF and other features\n",
    "* AS there is a class imbalance, performed SMOTE, but that didn't give the expected results. So dropped the idea\n",
    "* Taking note of high correlation between few pairs of Stock factors, experimented with PCA and it gave better results\n",
    "* Tried various models and settled on XGB\n",
    "* Experimented with stacking but it didn't give expected results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#!pip install imblearn\n",
    "#if the above command does not work to install imblearn package run the following command in your terminal\n",
    "# conda install -c glemaitre imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = '/kaggle/input/stock-prediction-using-sentiment-analysis/train_factors-1573207730757.csv'\n",
    "url2 = '/kaggle/input/stock-prediction-using-sentiment-analysis/jsonWsenti2.csv'\n",
    "url3 = '/kaggle/input/train-senti-updated-and-test-data-two-files-merged/json_train_senti69.csv'\n",
    "url4 = '/kaggle/input/test-data-with-weekday/test_data_merged_67.csv'\n",
    "url5 = '/kaggle/input/test-data-finallll/test_data_merged_32.csv'\n",
    "url6 = '/kaggle/input/finaaaaaal/test_data_merged_19.csv'\n",
    "url7 = '/kaggle/input/data-added-on-dec25/json_train_senti25.csv'\n",
    "url8 = '/kaggle/input/data-added-on-dec25/test_data_merged_25.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the train_factors file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id      date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
      "0   1  21/08/18  $NTAP -0.628652  0.988891 -0.055714  0.774379  0.551089   \n",
      "1   2  11/10/18  $WYNN  1.315786  1.438754  0.187327  0.608933 -1.153030   \n",
      "\n",
      "        SF6       SF7  alpha  \n",
      "0 -1.329229 -0.995539      2  \n",
      "1  1.859441  0.730995      3  \n",
      "(27006, 11)\n",
      "Id          int64\n",
      "date       object\n",
      "ticker     object\n",
      "SF1       float64\n",
      "SF2       float64\n",
      "SF3       float64\n",
      "SF4       float64\n",
      "SF5       float64\n",
      "SF6       float64\n",
      "SF7       float64\n",
      "alpha       int64\n",
      "dtype: object\n",
      "1304\n"
     ]
    }
   ],
   "source": [
    "train_factors = pd.read_csv(url1)\n",
    "print(train_factors.head(2))\n",
    "print(train_factors.shape)\n",
    "print(train_factors.dtypes)\n",
    "print(train_factors['ticker'].nunique())\n",
    "#total 1304 unqiue tickers which is way less than the ones in the train_json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating the date similar to the date in json file\n",
    "train_factors['date'] = pd.to_datetime(train_factors['date'],format=\"%d/%m/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-01 00:00:00\n",
      "2018-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_factors[\"date\"].min())\n",
    "print(train_factors[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$NTAP</td>\n",
       "      <td>-0.628652</td>\n",
       "      <td>0.988891</td>\n",
       "      <td>-0.055714</td>\n",
       "      <td>0.774379</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>-1.329229</td>\n",
       "      <td>-0.995539</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>$WYNN</td>\n",
       "      <td>1.315786</td>\n",
       "      <td>1.438754</td>\n",
       "      <td>0.187327</td>\n",
       "      <td>0.608933</td>\n",
       "      <td>-1.153030</td>\n",
       "      <td>1.859441</td>\n",
       "      <td>0.730995</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$DRI</td>\n",
       "      <td>-1.141388</td>\n",
       "      <td>-1.455016</td>\n",
       "      <td>0.332755</td>\n",
       "      <td>0.674502</td>\n",
       "      <td>0.111326</td>\n",
       "      <td>-0.478597</td>\n",
       "      <td>-1.488157</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>$ge</td>\n",
       "      <td>-0.054839</td>\n",
       "      <td>-1.454149</td>\n",
       "      <td>-0.162267</td>\n",
       "      <td>-0.681870</td>\n",
       "      <td>0.307869</td>\n",
       "      <td>-0.529987</td>\n",
       "      <td>0.404172</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>$FE</td>\n",
       "      <td>-0.686366</td>\n",
       "      <td>0.838865</td>\n",
       "      <td>0.073830</td>\n",
       "      <td>0.679024</td>\n",
       "      <td>0.329463</td>\n",
       "      <td>1.262782</td>\n",
       "      <td>-1.024042</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>September</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id       date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
       "0   1 2018-08-21  $NTAP -0.628652  0.988891 -0.055714  0.774379  0.551089   \n",
       "1   2 2018-10-11  $WYNN  1.315786  1.438754  0.187327  0.608933 -1.153030   \n",
       "2   3 2018-08-21   $DRI -1.141388 -1.455016  0.332755  0.674502  0.111326   \n",
       "3   4 2018-07-10    $ge -0.054839 -1.454149 -0.162267 -0.681870  0.307869   \n",
       "4   5 2018-09-12    $FE -0.686366  0.838865  0.073830  0.679024  0.329463   \n",
       "\n",
       "        SF6       SF7  alpha tweeted_day_of_week tweet_month  \n",
       "0 -1.329229 -0.995539      2             Tuesday      August  \n",
       "1  1.859441  0.730995      3            Thursday     October  \n",
       "2 -0.478597 -1.488157      1             Tuesday      August  \n",
       "3 -0.529987  0.404172      2             Tuesday        July  \n",
       "4  1.262782 -1.024042      2           Wednesday   September  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new factors weekday\n",
    "train_factors['tweeted_day_of_week'] = train_factors['date'].dt.weekday_name\n",
    "train_factors['tweet_month'] = train_factors['date'].dt.month_name()\n",
    "train_factors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_factors['date'] = pd.to_datetime(train_factors['date'],format=\"%d/%m/%y\").dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-01\n"
     ]
    }
   ],
   "source": [
    "print(train_factors[\"date\"].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No NA values\n",
    "#train_factors.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the train json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date ticker  senti_0  senti_1  senti_2  senti_3  senti_4  \\\n",
      "0  2018-07-01  $AABA      0.0      0.0      1.0      0.0      0.0   \n",
      "1  2018-07-01   $AAL      0.0      1.0      1.0      2.0      1.0   \n",
      "\n",
      "                                               tweet  word_count  senti_train  \\\n",
      "0  option volume x normal friday contract volume ...           8            2   \n",
      "1  s undervalue lowweek target zone markmonthly c...          28            3   \n",
      "\n",
      "  Senti_blob  \n",
      "0   positive  \n",
      "1    neutral  \n"
     ]
    }
   ],
   "source": [
    "train_senti = pd.read_csv(url7,index_col=[0])\n",
    "train_senti['date'] = pd.to_datetime(train_senti['date']).dt.date\n",
    "print(train_senti.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>senti_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "      <td>64482.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.411619</td>\n",
       "      <td>1.852377</td>\n",
       "      <td>6.905028</td>\n",
       "      <td>3.140303</td>\n",
       "      <td>2.361310</td>\n",
       "      <td>79.453351</td>\n",
       "      <td>2.031451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.257375</td>\n",
       "      <td>14.815434</td>\n",
       "      <td>47.012508</td>\n",
       "      <td>27.329722</td>\n",
       "      <td>19.408619</td>\n",
       "      <td>552.889254</td>\n",
       "      <td>0.940897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>866.000000</td>\n",
       "      <td>1086.000000</td>\n",
       "      <td>2508.000000</td>\n",
       "      <td>1673.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>31957.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            senti_0       senti_1       senti_2       senti_3       senti_4  \\\n",
       "count  64482.000000  64482.000000  64482.000000  64482.000000  64482.000000   \n",
       "mean       1.411619      1.852377      6.905028      3.140303      2.361310   \n",
       "std       12.257375     14.815434     47.012508     27.329722     19.408619   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      2.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      4.000000      1.000000      1.000000   \n",
       "max      866.000000   1086.000000   2508.000000   1673.000000   1107.000000   \n",
       "\n",
       "         word_count   senti_train  \n",
       "count  64482.000000  64482.000000  \n",
       "mean      79.453351      2.031451  \n",
       "std      552.889254      0.940897  \n",
       "min        1.000000      0.000000  \n",
       "25%        9.000000      2.000000  \n",
       "50%       17.000000      2.000000  \n",
       "75%       37.000000      2.000000  \n",
       "max    31957.000000      4.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_senti.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    45863\n",
      "1.0    11577\n",
      "2.0     2797\n",
      "3.0     1110\n",
      "4.0      665\n",
      "5.0      411\n",
      "6.0      306\n",
      "7.0      224\n",
      "8.0      151\n",
      "9.0      136\n",
      "Name: senti_0, dtype: int64\n",
      "Float64Index([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "print(train_senti['senti_0'].value_counts().head(10))\n",
    "#keeping only the top 10 levels in the column\n",
    "a = train_senti['senti_0'].value_counts()\n",
    "vals = a[:9].index\n",
    "print (vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      45863\n",
       "1.0      11577\n",
       "2.0       2797\n",
       "100.0     1242\n",
       "3.0       1110\n",
       "4.0        665\n",
       "5.0        411\n",
       "6.0        306\n",
       "7.0        224\n",
       "8.0        151\n",
       "9.0        136\n",
       "Name: senti_0, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_senti['senti_0'] = train_senti.senti_0.where(train_senti.senti_0.isin(vals), 100)\n",
    "train_senti['senti_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "train_senti['senti_1'].value_counts().head(10)\n",
    "b = train_senti['senti_1'].value_counts()\n",
    "vals2 = b[:9].index\n",
    "print (vals2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      40354\n",
       "1.0      13691\n",
       "2.0       3939\n",
       "3.0       1745\n",
       "100.0     1542\n",
       "4.0       1060\n",
       "5.0        758\n",
       "6.0        542\n",
       "7.0        401\n",
       "8.0        255\n",
       "9.0        195\n",
       "Name: senti_1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_senti['senti_1'] = train_senti.senti_1.where(train_senti.senti_1.isin(vals2), 100)\n",
    "train_senti['senti_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0,\n",
      "              12.0, 13.0, 14.0],\n",
      "             dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "train_senti['senti_2'].value_counts().head(15)\n",
    "c = train_senti['senti_2'].value_counts()\n",
    "vals3 = b[:14].index\n",
    "print (vals3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_senti['senti_2'] = train_senti.senti_2.where(train_senti.senti_2.isin(vals3), 100)\n",
    "#train_senti['senti_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "train_senti['senti_3'].value_counts().head(10)\n",
    "d = train_senti['senti_3'].value_counts()\n",
    "vals4 = d[:9].index\n",
    "print (vals4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_senti['senti_3'] = train_senti.senti_3.where(train_senti.senti_3.isin(vals4), 100)\n",
    "#train_senti['senti_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "train_senti['senti_4'].value_counts().head(10)\n",
    "e = train_senti['senti_4'].value_counts()\n",
    "vals5 = e[:9].index\n",
    "print (vals5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      43085\n",
       "1.0      10682\n",
       "2.0       3815\n",
       "100.0     2153\n",
       "3.0       1699\n",
       "4.0        984\n",
       "5.0        654\n",
       "6.0        522\n",
       "7.0        376\n",
       "8.0        289\n",
       "9.0        223\n",
       "Name: senti_4, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_senti['senti_4'] = train_senti.senti_4.where(train_senti.senti_4.isin(vals5), 100)\n",
    "train_senti['senti_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 9,  4, 10,  7,  6, 13,  8, 12,  5, 15, 16, 14, 11, 17, 19, 18,  3,\n",
      "            22, 20, 21, 23, 24, 25, 26, 27, 29, 28,  2, 30, 31, 32, 33, 36, 34,\n",
      "            35, 37, 38,  1, 39, 40, 41, 43, 45, 44, 42, 46, 47, 48, 49, 52],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#creating a new feature word count\n",
    "train_senti['word_count'].value_counts().head(50)\n",
    "f = train_senti['word_count'].value_counts()\n",
    "vals6 = f[:50].index\n",
    "print (vals6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_senti['word_count'] = train_senti.word_count.where(train_senti.word_count.isin(vals6), 100)\n",
    "#train_senti['word_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>Senti_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>$AABA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>option volume x normal friday contract volume ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>$AAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>s undervalue lowweek target zone markmonthly c...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>$AAP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>short sale volume short interest shortvolumes</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>$AAPL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>warren diggered exitright angle apple lol craz...</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>$ABBV</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bullish bat bullish bat bullish divergencewond...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker  senti_0  senti_1  senti_2  senti_3  senti_4  \\\n",
       "0  2018-07-01  $AABA      0.0      0.0      1.0      0.0      0.0   \n",
       "1  2018-07-01   $AAL      0.0      1.0      1.0      2.0      1.0   \n",
       "2  2018-07-01   $AAP      0.0      1.0      0.0      0.0      0.0   \n",
       "3  2018-07-01  $AAPL      1.0      2.0    100.0      5.0      2.0   \n",
       "4  2018-07-01  $ABBV      2.0      0.0      0.0      0.0      1.0   \n",
       "\n",
       "                                               tweet  word_count  senti_train  \\\n",
       "0  option volume x normal friday contract volume ...           8            2   \n",
       "1  s undervalue lowweek target zone markmonthly c...          28            3   \n",
       "2      short sale volume short interest shortvolumes           6            1   \n",
       "3  warren diggered exitright angle apple lol craz...         100            4   \n",
       "4  bullish bat bullish bat bullish divergencewond...          16            0   \n",
       "\n",
       "  Senti_blob  \n",
       "0   positive  \n",
       "1    neutral  \n",
       "2    neutral  \n",
       "3   positive  \n",
       "4    neutral  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date ticker  senti_0  senti_1  senti_2  senti_3  senti_4  word_count  \\\n",
      "0  2018-07-01  $AABA      0.0      0.0      1.0      0.0      0.0           8   \n",
      "1  2018-07-01   $AAL      0.0      1.0      1.0      2.0      1.0          28   \n",
      "\n",
      "   senti_train Senti_blob  \n",
      "0            2   positive  \n",
      "1            3    neutral  \n"
     ]
    }
   ],
   "source": [
    "#Dropping the tweet column\n",
    "train_senti = train_senti.drop(['tweet'],axis=1)\n",
    "print(train_senti.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097\n",
      "(64482, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_senti['ticker'].nunique())\n",
    "print(train_senti.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the trian factors and train json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = pd.merge(train_factors, train_senti,  how='left', left_on=['date','ticker'], right_on = ['date','ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id        date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
      "0   1  2018-08-21  $NTAP -0.628652  0.988891 -0.055714  0.774379  0.551089   \n",
      "1   2  2018-10-11  $WYNN  1.315786  1.438754  0.187327  0.608933 -1.153030   \n",
      "2   3  2018-08-21   $DRI -1.141388 -1.455016  0.332755  0.674502  0.111326   \n",
      "3   4  2018-07-10    $ge -0.054839 -1.454149 -0.162267 -0.681870  0.307869   \n",
      "4   5  2018-09-12    $FE -0.686366  0.838865  0.073830  0.679024  0.329463   \n",
      "\n",
      "        SF6       SF7  ...  tweeted_day_of_week tweet_month senti_0  senti_1  \\\n",
      "0 -1.329229 -0.995539  ...              Tuesday      August     0.0      3.0   \n",
      "1  1.859441  0.730995  ...             Thursday     October     1.0      2.0   \n",
      "2 -0.478597 -1.488157  ...              Tuesday      August     0.0      1.0   \n",
      "3 -0.529987  0.404172  ...              Tuesday        July     0.0      0.0   \n",
      "4  1.262782 -1.024042  ...            Wednesday   September     1.0      0.0   \n",
      "\n",
      "   senti_2  senti_3  senti_4  word_count  senti_train  Senti_blob  \n",
      "0      7.0      2.0      1.0       100.0          2.0    negative  \n",
      "1      8.0      3.0      1.0       100.0          4.0    positive  \n",
      "2      2.0      0.0      0.0        24.0          2.0    positive  \n",
      "3      4.0      0.0      0.0        13.0          2.0     neutral  \n",
      "4      0.0      0.0      0.0         8.0          0.0     neutral  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(27006, 21)\n",
      "(27006, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_merged.head())\n",
    "print(train_merged.shape)\n",
    "print(train_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "date                      0\n",
       "ticker                    0\n",
       "SF1                       0\n",
       "SF2                       0\n",
       "SF3                       0\n",
       "SF4                       0\n",
       "SF5                       0\n",
       "SF6                       0\n",
       "SF7                       0\n",
       "alpha                     0\n",
       "tweeted_day_of_week       0\n",
       "tweet_month               0\n",
       "senti_0                2702\n",
       "senti_1                2702\n",
       "senti_2                2702\n",
       "senti_3                2702\n",
       "senti_4                2702\n",
       "word_count             2702\n",
       "senti_train            2702\n",
       "Senti_blob             2702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.isna().sum()\n",
    "#train_merged.to_csv(\"train_merged.csv\")\n",
    "##There are NA vlaues in the final file as few stocks do not have any tweets on a particular day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n",
      "16\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(train_merged['senti_0'].nunique())\n",
    "print(train_merged['senti_1'].nunique())\n",
    "print(train_merged['senti_2'].nunique())\n",
    "print(train_merged['senti_3'].nunique())\n",
    "print(train_merged['senti_4'].nunique())\n",
    "#Lot of unique values. They have to be numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id        date ticker       SF1       SF2       SF3       SF4       SF5  \\\n",
      "0   1  2018-08-21  $NTAP -0.628652  0.988891 -0.055714  0.774379  0.551089   \n",
      "\n",
      "        SF6       SF7  ...  tweeted_day_of_week tweet_month senti_0  senti_1  \\\n",
      "0 -1.329229 -0.995539  ...              Tuesday      August     0.0      3.0   \n",
      "\n",
      "   senti_2  senti_3  senti_4  word_count  senti_train  Senti_blob  \n",
      "0      7.0      2.0      1.0       100.0          2.0    negative  \n",
      "\n",
      "[1 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exporting the merge file to study the output and also to use it for further analysis in another kernel\n",
    "print(train_merged.head(1))\n",
    "train_merged.to_csv(\"train_merged_ANN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'date', 'ticker', 'SF1', 'SF2', 'SF3', 'SF4', 'SF5', 'SF6', 'SF7',\n",
       "       'alpha', 'tweeted_day_of_week', 'tweet_month', 'senti_0', 'senti_1',\n",
       "       'senti_2', 'senti_3', 'senti_4', 'word_count', 'senti_train',\n",
       "       'Senti_blob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA on Stock Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit_transform(train_merged[['SF1','SF2','SF3','SF4','SF5','SF6','SF7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40159267, 0.18226381, 0.1487232 , 0.14352884, 0.12389148])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_\n",
    "#around 99% of the total variance is explained by 5 principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.7% of the variance is explained by 5 principal components. So, replacing the 7 stock factors with 5 Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['pc1','pc2','pc3','pc4','pc5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>Senti_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$NTAP</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>$WYNN</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>October</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$DRI</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>$ge</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>July</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>$FE</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>September</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        date ticker  alpha tweeted_day_of_week tweet_month  senti_0  \\\n",
       "0   1  2018-08-21  $NTAP      2             Tuesday      August      0.0   \n",
       "1   2  2018-10-11  $WYNN      3            Thursday     October      1.0   \n",
       "2   3  2018-08-21   $DRI      1             Tuesday      August      0.0   \n",
       "3   4  2018-07-10    $ge      2             Tuesday        July      0.0   \n",
       "4   5  2018-09-12    $FE      2           Wednesday   September      1.0   \n",
       "\n",
       "   senti_1  senti_2  senti_3  senti_4  word_count  senti_train Senti_blob  \n",
       "0      3.0      7.0      2.0      1.0       100.0          2.0   negative  \n",
       "1      2.0      8.0      3.0      1.0       100.0          4.0   positive  \n",
       "2      1.0      2.0      0.0      0.0        24.0          2.0   positive  \n",
       "3      0.0      4.0      0.0      0.0        13.0          2.0    neutral  \n",
       "4      0.0      0.0      0.0      0.0         8.0          0.0    neutral  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping SF1 to SF7 from the train_merged file\n",
    "train_merged = train_merged.drop(['SF1','SF2','SF3','SF4','SF5','SF6','SF7'],axis=1)\n",
    "train_merged.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>Senti_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.403016</td>\n",
       "      <td>-0.523298</td>\n",
       "      <td>1.650719</td>\n",
       "      <td>-0.131778</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$NTAP</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.655437</td>\n",
       "      <td>1.677647</td>\n",
       "      <td>-0.518593</td>\n",
       "      <td>2.367071</td>\n",
       "      <td>-0.706860</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>$WYNN</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>October</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.036669</td>\n",
       "      <td>-0.288522</td>\n",
       "      <td>-0.564479</td>\n",
       "      <td>-1.396427</td>\n",
       "      <td>0.364319</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$DRI</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.585419</td>\n",
       "      <td>-0.359531</td>\n",
       "      <td>-0.529225</td>\n",
       "      <td>-1.470591</td>\n",
       "      <td>0.343630</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>$ge</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>July</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.413565</td>\n",
       "      <td>-0.458076</td>\n",
       "      <td>-0.401093</td>\n",
       "      <td>1.457988</td>\n",
       "      <td>-0.125572</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>$FE</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>September</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5  Id        date ticker  \\\n",
       "0  1.403016 -0.523298  1.650719 -0.131778 -0.405763   1  2018-08-21  $NTAP   \n",
       "1 -0.655437  1.677647 -0.518593  2.367071 -0.706860   2  2018-10-11  $WYNN   \n",
       "2  2.036669 -0.288522 -0.564479 -1.396427  0.364319   3  2018-08-21   $DRI   \n",
       "3 -0.585419 -0.359531 -0.529225 -1.470591  0.343630   4  2018-07-10    $ge   \n",
       "4  1.413565 -0.458076 -0.401093  1.457988 -0.125572   5  2018-09-12    $FE   \n",
       "\n",
       "   alpha tweeted_day_of_week tweet_month  senti_0  senti_1  senti_2  senti_3  \\\n",
       "0      2             Tuesday      August      0.0      3.0      7.0      2.0   \n",
       "1      3            Thursday     October      1.0      2.0      8.0      3.0   \n",
       "2      1             Tuesday      August      0.0      1.0      2.0      0.0   \n",
       "3      2             Tuesday        July      0.0      0.0      4.0      0.0   \n",
       "4      2           Wednesday   September      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   senti_4  word_count  senti_train Senti_blob  \n",
       "0      1.0       100.0          2.0   negative  \n",
       "1      1.0       100.0          4.0   positive  \n",
       "2      0.0        24.0          2.0   positive  \n",
       "3      0.0        13.0          2.0    neutral  \n",
       "4      0.0         8.0          0.0    neutral  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged = pd.concat([principalDf, train_merged], axis = 1)\n",
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to respective data types\n",
    "for col in [ 'date','ticker', 'alpha', 'tweeted_day_of_week', 'tweet_month', 'senti_train','Senti_blob','senti_0',\n",
    "            'senti_1','senti_2','senti_3','senti_4','word_count']:\n",
    "    train_merged[col] = train_merged[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['pc1', 'pc2', 'pc3', 'pc4', 'pc5']:\n",
    "    train_merged[col] = train_merged[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>Senti_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.403016</td>\n",
       "      <td>-0.523298</td>\n",
       "      <td>1.650719</td>\n",
       "      <td>-0.131778</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$NTAP</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.655437</td>\n",
       "      <td>1.677647</td>\n",
       "      <td>-0.518593</td>\n",
       "      <td>2.367071</td>\n",
       "      <td>-0.706860</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>$WYNN</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>October</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.036669</td>\n",
       "      <td>-0.288522</td>\n",
       "      <td>-0.564479</td>\n",
       "      <td>-1.396427</td>\n",
       "      <td>0.364319</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>$DRI</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>August</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.585419</td>\n",
       "      <td>-0.359531</td>\n",
       "      <td>-0.529225</td>\n",
       "      <td>-1.470591</td>\n",
       "      <td>0.343630</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-10</td>\n",
       "      <td>$ge</td>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>July</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.413565</td>\n",
       "      <td>-0.458076</td>\n",
       "      <td>-0.401093</td>\n",
       "      <td>1.457988</td>\n",
       "      <td>-0.125572</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>$FE</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>September</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5  Id       date ticker  \\\n",
       "0  1.403016 -0.523298  1.650719 -0.131778 -0.405763   1 2018-08-21  $NTAP   \n",
       "1 -0.655437  1.677647 -0.518593  2.367071 -0.706860   2 2018-10-11  $WYNN   \n",
       "2  2.036669 -0.288522 -0.564479 -1.396427  0.364319   3 2018-08-21   $DRI   \n",
       "3 -0.585419 -0.359531 -0.529225 -1.470591  0.343630   4 2018-07-10    $ge   \n",
       "4  1.413565 -0.458076 -0.401093  1.457988 -0.125572   5 2018-09-12    $FE   \n",
       "\n",
       "  alpha tweeted_day_of_week tweet_month senti_0 senti_1 senti_2 senti_3  \\\n",
       "0     2             Tuesday      August     0.0     3.0     7.0     2.0   \n",
       "1     3            Thursday     October     1.0     2.0     8.0     3.0   \n",
       "2     1             Tuesday      August     0.0     1.0     2.0     0.0   \n",
       "3     2             Tuesday        July     0.0     0.0     4.0     0.0   \n",
       "4     2           Wednesday   September     1.0     0.0     0.0     0.0   \n",
       "\n",
       "  senti_4 word_count senti_train Senti_blob  \n",
       "0     1.0      100.0         2.0   negative  \n",
       "1     1.0      100.0         4.0   positive  \n",
       "2     0.0       24.0         2.0   positive  \n",
       "3     0.0       13.0         2.0    neutral  \n",
       "4     0.0        8.0         0.0    neutral  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged = train_merged.drop(['Id','Senti_blob',\n",
    "            'date','ticker','tweet_month'],axis=1)\n",
    "#train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27006, 13) (27006,)\n"
     ]
    }
   ],
   "source": [
    "X = train_merged.drop([\"alpha\"], axis = 1)\n",
    "Y= train_merged[\"alpha\"]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc1                       0\n",
       "pc2                       0\n",
       "pc3                       0\n",
       "pc4                       0\n",
       "pc5                       0\n",
       "tweeted_day_of_week       0\n",
       "senti_0                2702\n",
       "senti_1                2702\n",
       "senti_2                2702\n",
       "senti_3                2702\n",
       "senti_4                2702\n",
       "word_count             2702\n",
       "senti_train            2702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18904, 13)\n",
      "(8102, 13)\n",
      "(18904,)\n",
      "(8102,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alpha', 'tweeted_day_of_week', 'senti_0', 'senti_1', 'senti_2', 'senti_3', 'senti_4', 'word_count', 'senti_train']\n",
      "['pc1', 'pc2', 'pc3', 'pc4', 'pc5']\n"
     ]
    }
   ],
   "source": [
    "cat_attr = list(train_merged.select_dtypes(\"category\").columns)\n",
    "num_attr = list(train_merged.columns.difference(cat_attr))\n",
    "\n",
    "print(cat_attr)\n",
    "print(num_attr)\n",
    "cat_attr.remove('alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pc1                       0\n",
       "pc2                       0\n",
       "pc3                       0\n",
       "pc4                       0\n",
       "pc5                       0\n",
       "tweeted_day_of_week       0\n",
       "senti_0                1900\n",
       "senti_1                1900\n",
       "senti_2                1900\n",
       "senti_3                1900\n",
       "senti_4                1900\n",
       "word_count             1900\n",
       "senti_train            1900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_train[cat_attr] = pd.DataFrame(SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit_transform(X_train[cat_attr]),\n",
    "                       columns= X_train[cat_attr].columns)\n",
    "\n",
    "X_test[cat_attr] = pd.DataFrame(SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit_transform(X_test[cat_attr]),\n",
    "                       columns= X_test[cat_attr].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummifying the categorical variables\n",
    "X_train = pd.get_dummies(X_train, prefix_sep='_', drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>tweeted_day_of_week_Monday</th>\n",
       "      <th>tweeted_day_of_week_Saturday</th>\n",
       "      <th>tweeted_day_of_week_Sunday</th>\n",
       "      <th>tweeted_day_of_week_Thursday</th>\n",
       "      <th>tweeted_day_of_week_Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_46.0</th>\n",
       "      <th>word_count_47.0</th>\n",
       "      <th>word_count_48.0</th>\n",
       "      <th>word_count_49.0</th>\n",
       "      <th>word_count_52.0</th>\n",
       "      <th>word_count_100.0</th>\n",
       "      <th>senti_train_1.0</th>\n",
       "      <th>senti_train_2.0</th>\n",
       "      <th>senti_train_3.0</th>\n",
       "      <th>senti_train_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21056</th>\n",
       "      <td>-0.635508</td>\n",
       "      <td>-0.220949</td>\n",
       "      <td>0.527436</td>\n",
       "      <td>0.254129</td>\n",
       "      <td>-0.459915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17272</th>\n",
       "      <td>0.373459</td>\n",
       "      <td>-0.147792</td>\n",
       "      <td>1.434028</td>\n",
       "      <td>-1.038725</td>\n",
       "      <td>0.376016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>-1.967386</td>\n",
       "      <td>0.287762</td>\n",
       "      <td>-0.054873</td>\n",
       "      <td>0.443289</td>\n",
       "      <td>0.688367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24702</th>\n",
       "      <td>3.733390</td>\n",
       "      <td>0.225310</td>\n",
       "      <td>-1.127994</td>\n",
       "      <td>-0.142853</td>\n",
       "      <td>0.873132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20574</th>\n",
       "      <td>0.082064</td>\n",
       "      <td>1.998709</td>\n",
       "      <td>1.379938</td>\n",
       "      <td>-0.281231</td>\n",
       "      <td>-0.424185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pc1       pc2       pc3       pc4       pc5  \\\n",
       "21056 -0.635508 -0.220949  0.527436  0.254129 -0.459915   \n",
       "17272  0.373459 -0.147792  1.434028 -1.038725  0.376016   \n",
       "18342 -1.967386  0.287762 -0.054873  0.443289  0.688367   \n",
       "24702  3.733390  0.225310 -1.127994 -0.142853  0.873132   \n",
       "20574  0.082064  1.998709  1.379938 -0.281231 -0.424185   \n",
       "\n",
       "       tweeted_day_of_week_Monday  tweeted_day_of_week_Saturday  \\\n",
       "21056                           0                             0   \n",
       "17272                           0                             0   \n",
       "18342                           0                             0   \n",
       "24702                           0                             0   \n",
       "20574                           0                             0   \n",
       "\n",
       "       tweeted_day_of_week_Sunday  tweeted_day_of_week_Thursday  \\\n",
       "21056                           0                             0   \n",
       "17272                           1                             0   \n",
       "18342                           0                             0   \n",
       "24702                           0                             0   \n",
       "20574                           0                             0   \n",
       "\n",
       "       tweeted_day_of_week_Tuesday  ...  word_count_46.0  word_count_47.0  \\\n",
       "21056                            0  ...                0                0   \n",
       "17272                            0  ...                0                0   \n",
       "18342                            1  ...                0                0   \n",
       "24702                            0  ...                0                0   \n",
       "20574                            0  ...                0                0   \n",
       "\n",
       "       word_count_48.0  word_count_49.0  word_count_52.0  word_count_100.0  \\\n",
       "21056                0                0                0                 0   \n",
       "17272                0                0                0                 0   \n",
       "18342                0                0                0                 0   \n",
       "24702                0                0                0                 0   \n",
       "20574                0                0                0                 0   \n",
       "\n",
       "       senti_train_1.0  senti_train_2.0  senti_train_3.0  senti_train_4.0  \n",
       "21056                0                0                0                0  \n",
       "17272                0                1                0                0  \n",
       "18342                1                0                0                0  \n",
       "24702                0                0                0                0  \n",
       "20574                0                0                0                0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4427634363097757\n",
      "0.4434707479634658\n",
      "F1 score for logreg Train Data is  0.33961553169036507\n",
      "F1 score for logreg Test Data is  0.33149388355810394\n"
     ]
    }
   ],
   "source": [
    "train_pred_logreg = clf_logreg.predict(X_train)\n",
    "test_pred_logreg = clf_logreg.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_true=Y_train, y_pred = train_pred_logreg))\n",
    "\n",
    "print(accuracy_score(y_true=Y_train, y_pred=train_pred_logreg))\n",
    "print(accuracy_score(y_true=Y_test, y_pred=test_pred_logreg))\n",
    "\n",
    "\n",
    "f1_logreg_train = f1_score(y_true=Y_train, y_pred=train_pred_logreg,average='weighted')\n",
    "f1_logreg_test = f1_score(y_true=Y_test, y_pred=test_pred_logreg,average='weighted')\n",
    "\n",
    "print(\"F1 score for logreg Train Data is \",f1_logreg_train)\n",
    "print(\"F1 score for logreg Test Data is \",f1_logreg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 844 ms, sys: 144 ms, total: 988 ms\n",
      "Wall time: 778 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['entropy'], 'max_depth': [3],\n",
       "                         'min_samples_leaf': [5], 'min_samples_split': [10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_dt =  DecisionTreeClassifier()\n",
    "\n",
    "dt_param_grid = {'criterion': ['entropy'], 'max_depth': [3], \n",
    "                 \"min_samples_split\": [10],\"min_samples_leaf\": [5]\n",
    "                }\n",
    "\n",
    "dt_grid_bal = GridSearchCV(clf_dt, param_grid=dt_param_grid, cv=5)\n",
    "\n",
    "dt_grid_bal.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 10}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt_grid_bal.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5198899703766399\n",
      "0.5280177733892866\n",
      "F1 score for decison tree model is  0.4229266368025551\n",
      "F1 score for decison tree model is  0.43052135641084877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_pred_dt = dt_grid_bal.predict(X_train)\n",
    "test_pred_dt = dt_grid_bal.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_true=Y_train, y_pred = train_pred_logreg))\n",
    "\n",
    "print(accuracy_score(y_true=Y_train, y_pred=train_pred_dt))\n",
    "print(accuracy_score(y_true=Y_test, y_pred=test_pred_dt))\n",
    "\n",
    "train_pred_dt\n",
    "f1_logreg_train_dt = f1_score(y_true=Y_train, y_pred=train_pred_dt,average='weighted')\n",
    "f1_logreg_test_dt = f1_score(y_true=Y_test, y_pred=test_pred_dt,average='weighted')\n",
    "\n",
    "print(\"F1 score for decison tree model is \",f1_logreg_train_dt)\n",
    "print(\"F1 score for decison tree model is \",f1_logreg_test_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1508pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 1508.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 1504,-429 1504,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"#d2f9ce\" stroke=\"black\" d=\"M909.5,-425C909.5,-425 718.5,-425 718.5,-425 712.5,-425 706.5,-419 706.5,-413 706.5,-413 706.5,-354 706.5,-354 706.5,-348 712.5,-342 718.5,-342 718.5,-342 909.5,-342 909.5,-342 915.5,-342 921.5,-348 921.5,-354 921.5,-354 921.5,-413 921.5,-413 921.5,-419 915.5,-425 909.5,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"778\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc5  1.081</text>\n",
       "<text text-anchor=\"start\" x=\"770\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.92</text>\n",
       "<text text-anchor=\"start\" x=\"761.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18904</text>\n",
       "<text text-anchor=\"start\" x=\"714.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3873, 7587, 3879, 3565]</text>\n",
       "<text text-anchor=\"start\" x=\"786.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#cbf8c7\" stroke=\"black\" d=\"M759.5,-306C759.5,-306 568.5,-306 568.5,-306 562.5,-306 556.5,-300 556.5,-294 556.5,-294 556.5,-235 556.5,-235 556.5,-229 562.5,-223 568.5,-223 568.5,-223 759.5,-223 759.5,-223 765.5,-223 771.5,-229 771.5,-235 771.5,-235 771.5,-294 771.5,-294 771.5,-300 765.5,-306 759.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"626\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc5  &#45;0.518</text>\n",
       "<text text-anchor=\"start\" x=\"616.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.886</text>\n",
       "<text text-anchor=\"start\" x=\"611.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17064</text>\n",
       "<text text-anchor=\"start\" x=\"564.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2978, 7361, 3215, 3510]</text>\n",
       "<text text-anchor=\"start\" x=\"636.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M761.958,-341.907C749.742,-332.379 736.626,-322.148 724.089,-312.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"725.987,-309.411 715.95,-306.021 721.682,-314.931 725.987,-309.411\"/>\n",
       "<text text-anchor=\"middle\" x=\"719.016\" y=\"-327.132\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<path fill=\"#fae6d8\" stroke=\"black\" d=\"M1040.5,-306C1040.5,-306 887.5,-306 887.5,-306 881.5,-306 875.5,-300 875.5,-294 875.5,-294 875.5,-235 875.5,-235 875.5,-229 881.5,-223 887.5,-223 887.5,-223 1040.5,-223 1040.5,-223 1046.5,-223 1052.5,-229 1052.5,-235 1052.5,-235 1052.5,-294 1052.5,-294 1052.5,-300 1046.5,-306 1040.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"926\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc1  &#45;2.221</text>\n",
       "<text text-anchor=\"start\" x=\"916.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.559</text>\n",
       "<text text-anchor=\"start\" x=\"915.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1840</text>\n",
       "<text text-anchor=\"start\" x=\"883.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [895, 226, 664, 55]</text>\n",
       "<text text-anchor=\"start\" x=\"936.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M866.042,-341.907C878.258,-332.379 891.374,-322.148 903.911,-312.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"906.318,-314.931 912.05,-306.021 902.013,-309.411 906.318,-314.931\"/>\n",
       "<text text-anchor=\"middle\" x=\"908.984\" y=\"-327.132\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"#f6fbfe\" stroke=\"black\" d=\"M383,-187C383,-187 207,-187 207,-187 201,-187 195,-181 195,-175 195,-175 195,-116 195,-116 195,-110 201,-104 207,-104 207,-104 383,-104 383,-104 389,-104 395,-110 395,-116 395,-116 395,-175 395,-175 395,-181 389,-187 383,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"259\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc1  1.827</text>\n",
       "<text text-anchor=\"start\" x=\"247.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.936</text>\n",
       "<text text-anchor=\"start\" x=\"246.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3899</text>\n",
       "<text text-anchor=\"start\" x=\"203\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [901, 553, 1285, 1160]</text>\n",
       "<text text-anchor=\"start\" x=\"267.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M556.278,-229.344C508.713,-214.263 452.863,-196.554 405.035,-181.389\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"405.859,-177.979 395.269,-178.293 403.744,-184.652 405.859,-177.979\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<path fill=\"#b3f4ad\" stroke=\"black\" d=\"M759.5,-187C759.5,-187 568.5,-187 568.5,-187 562.5,-187 556.5,-181 556.5,-175 556.5,-175 556.5,-116 556.5,-116 556.5,-110 562.5,-104 568.5,-104 568.5,-104 759.5,-104 759.5,-104 765.5,-104 771.5,-110 771.5,-116 771.5,-116 771.5,-175 771.5,-175 771.5,-181 765.5,-187 759.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"628\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc5  0.141</text>\n",
       "<text text-anchor=\"start\" x=\"616.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.762</text>\n",
       "<text text-anchor=\"start\" x=\"611.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13165</text>\n",
       "<text text-anchor=\"start\" x=\"564.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2077, 6808, 1930, 2350]</text>\n",
       "<text text-anchor=\"start\" x=\"636.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M664,-222.907C664,-214.649 664,-205.864 664,-197.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"667.5,-197.021 664,-187.021 660.5,-197.021 667.5,-197.021\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<path fill=\"#feffff\" stroke=\"black\" d=\"M180,-68C180,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 180,-0 180,-0 186,-0 192,-6 192,-12 192,-12 192,-56 192,-56 192,-62 186,-68 180,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"48.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.706</text>\n",
       "<text text-anchor=\"start\" x=\"47.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3179</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [886, 79, 1112, 1102]</text>\n",
       "<text text-anchor=\"start\" x=\"68.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221.183,-103.882C202.741,-93.7346 183.037,-82.8922 164.847,-72.8832\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.5,-69.7978 156.051,-68.0433 163.125,-75.9307 166.5,-69.7978\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<path fill=\"#9af192\" stroke=\"black\" d=\"M368,-68C368,-68 222,-68 222,-68 216,-68 210,-62 210,-56 210,-56 210,-12 210,-12 210,-6 216,-0 222,-0 222,-0 368,-0 368,-0 374,-0 380,-6 380,-12 380,-12 380,-56 380,-56 380,-62 374,-68 368,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"255\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.3</text>\n",
       "<text text-anchor=\"start\" x=\"250\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 720</text>\n",
       "<text text-anchor=\"start\" x=\"218\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 474, 173, 58]</text>\n",
       "<text text-anchor=\"start\" x=\"267.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M295,-103.726C295,-95.5175 295,-86.8595 295,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.5,-78.2996 295,-68.2996 291.5,-78.2996 298.5,-78.2996\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<path fill=\"#9df195\" stroke=\"black\" d=\"M586,-68C586,-68 410,-68 410,-68 404,-68 398,-62 398,-56 398,-56 398,-12 398,-12 398,-6 404,-0 410,-0 410,-0 586,-0 586,-0 592,-0 598,-6 598,-12 598,-12 598,-56 598,-56 598,-62 592,-68 586,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"450.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.552</text>\n",
       "<text text-anchor=\"start\" x=\"449.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8071</text>\n",
       "<text text-anchor=\"start\" x=\"406\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [795, 4972, 901, 1403]</text>\n",
       "<text text-anchor=\"start\" x=\"470.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M602.188,-103.726C587.316,-93.9161 571.471,-83.4644 556.744,-73.7496\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"558.492,-70.7099 548.217,-68.1252 554.637,-76.5532 558.492,-70.7099\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<path fill=\"#e4fbe2\" stroke=\"black\" d=\"M811.5,-68C811.5,-68 628.5,-68 628.5,-68 622.5,-68 616.5,-62 616.5,-56 616.5,-56 616.5,-12 616.5,-12 616.5,-6 622.5,-0 628.5,-0 628.5,-0 811.5,-0 811.5,-0 817.5,-0 823.5,-6 823.5,-12 823.5,-12 823.5,-56 823.5,-56 823.5,-62 817.5,-68 811.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"672.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.949</text>\n",
       "<text text-anchor=\"start\" x=\"671.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5094</text>\n",
       "<text text-anchor=\"start\" x=\"624.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1282, 1836, 1029, 947]</text>\n",
       "<text text-anchor=\"start\" x=\"692.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M684.852,-103.726C689.237,-95.1527 693.872,-86.0891 698.288,-77.4555\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"701.533,-78.7965 702.97,-68.2996 695.301,-75.6092 701.533,-78.7965\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<path fill=\"#73eb69\" stroke=\"black\" d=\"M1033,-187C1033,-187 895,-187 895,-187 889,-187 883,-181 883,-175 883,-175 883,-116 883,-116 883,-110 889,-104 895,-104 895,-104 1033,-104 1033,-104 1039,-104 1045,-110 1045,-116 1045,-116 1045,-175 1045,-175 1045,-181 1039,-187 1033,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"926\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc2  &#45;0.468</text>\n",
       "<text text-anchor=\"start\" x=\"916.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.063</text>\n",
       "<text text-anchor=\"start\" x=\"919\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 271</text>\n",
       "<text text-anchor=\"start\" x=\"891\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 213, 17, 11]</text>\n",
       "<text text-anchor=\"start\" x=\"936.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M964,-222.907C964,-214.649 964,-205.864 964,-197.302\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"967.5,-197.021 964,-187.021 960.5,-197.021 967.5,-197.021\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<path fill=\"#f9e1d0\" stroke=\"black\" d=\"M1312,-187C1312,-187 1166,-187 1166,-187 1160,-187 1154,-181 1154,-175 1154,-175 1154,-116 1154,-116 1154,-110 1160,-104 1166,-104 1166,-104 1312,-104 1312,-104 1318,-104 1324,-110 1324,-116 1324,-116 1324,-175 1324,-175 1324,-181 1318,-187 1312,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"1203\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pc2  0.233</text>\n",
       "<text text-anchor=\"start\" x=\"1191.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.203</text>\n",
       "<text text-anchor=\"start\" x=\"1190.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1569</text>\n",
       "<text text-anchor=\"start\" x=\"1162\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [865, 13, 647, 44]</text>\n",
       "<text text-anchor=\"start\" x=\"1211.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>8&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1052.53,-225.836C1081.85,-213.359 1114.6,-199.426 1144.37,-186.761\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1146.09,-189.833 1153.92,-182.697 1143.35,-183.391 1146.09,-189.833\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<path fill=\"#a2d1f3\" stroke=\"black\" d=\"M962,-68C962,-68 854,-68 854,-68 848,-68 842,-62 842,-56 842,-56 842,-12 842,-12 842,-6 848,-0 854,-0 854,-0 962,-0 962,-0 968,-0 974,-6 974,-12 974,-12 974,-56 974,-56 974,-62 968,-68 962,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"860.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.529</text>\n",
       "<text text-anchor=\"start\" x=\"867\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n",
       "<text text-anchor=\"start\" x=\"850\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1, 13, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"880.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M943.148,-103.726C938.763,-95.1527 934.128,-86.0891 929.712,-77.4555\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"932.699,-75.6092 925.03,-68.2996 926.467,-78.7965 932.699,-75.6092\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\n",
       "<path fill=\"#65e95a\" stroke=\"black\" d=\"M1127.5,-68C1127.5,-68 1004.5,-68 1004.5,-68 998.5,-68 992.5,-62 992.5,-56 992.5,-56 992.5,-12 992.5,-12 992.5,-6 998.5,-0 1004.5,-0 1004.5,-0 1127.5,-0 1127.5,-0 1133.5,-0 1139.5,-6 1139.5,-12 1139.5,-12 1139.5,-56 1139.5,-56 1139.5,-62 1133.5,-68 1127.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1018.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.786</text>\n",
       "<text text-anchor=\"start\" x=\"1021\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 249</text>\n",
       "<text text-anchor=\"start\" x=\"1000.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 212, 4, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"1038.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 2</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1001.98,-103.726C1010.48,-94.6054 1019.49,-84.93 1027.99,-75.8078\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1030.73,-78.0025 1034.98,-68.2996 1025.6,-73.2312 1030.73,-78.0025\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<path fill=\"#84c2ef\" stroke=\"black\" d=\"M1308,-68C1308,-68 1170,-68 1170,-68 1164,-68 1158,-62 1158,-56 1158,-56 1158,-12 1158,-12 1158,-6 1164,-0 1170,-0 1170,-0 1308,-0 1308,-0 1314,-0 1320,-6 1320,-12 1320,-12 1320,-56 1320,-56 1320,-62 1314,-68 1308,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1191.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.021</text>\n",
       "<text text-anchor=\"start\" x=\"1194\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 740</text>\n",
       "<text text-anchor=\"start\" x=\"1166\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [187, 6, 531, 16]</text>\n",
       "<text text-anchor=\"start\" x=\"1211.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 3</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1239,-103.726C1239,-95.5175 1239,-86.8595 1239,-78.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1242.5,-78.2996 1239,-68.2996 1235.5,-78.2996 1242.5,-78.2996\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<path fill=\"#eb9c63\" stroke=\"black\" d=\"M1488,-68C1488,-68 1350,-68 1350,-68 1344,-68 1338,-62 1338,-56 1338,-56 1338,-12 1338,-12 1338,-6 1344,-0 1350,-0 1350,-0 1488,-0 1488,-0 1494,-0 1500,-6 1500,-12 1500,-12 1500,-56 1500,-56 1500,-62 1494,-68 1488,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"1371.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.858</text>\n",
       "<text text-anchor=\"start\" x=\"1374\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 829</text>\n",
       "<text text-anchor=\"start\" x=\"1346\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [678, 7, 116, 28]</text>\n",
       "<text text-anchor=\"start\" x=\"1391.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1305.77,-103.882C1322.15,-93.9191 1339.63,-83.2862 1355.83,-73.4299\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1357.96,-76.2308 1364.68,-68.0433 1354.32,-70.2504 1357.96,-76.2308\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fe6b85a5668>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt_grid_bal.best_estimator_, out_file=None, \n",
    "                                feature_names=X_train.columns,\n",
    "                                class_names=['1','2','3','4'], \n",
    "                                filled=True, rounded=True, special_characters=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6b9085710>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAE2CAYAAACtJt9GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVXW9//HXh+GuiIpkIRKYeIFErPGSNygi8ISQhjnaT8XkoCZHO50yrZOe4wnzdiwxL2mCZpzwljhHKUtNU1NwUPQESo2AMlGKomgq6ODn98f3O8xyu/fMnpm1914zvJ+Px37M3mut/V2f9d1r9mev9f2u7zJ3R0REJE3dKh2AiIh0PUouIiKSOiUXERFJnZKLiIikTslFRERSp+QiIiKpU3IREZHUFZVczGyima0ws3ozOyfP/F5mdkucv8jMhibmnRunrzCzCa2VaWYPm9nS+FhrZgs6tokiIlJu1tpFlGZWBfwZGA80AE8Ax7n78sQyXwdGuftpZlYDHOXux5rZCOCXwAHAIOA+YI/4thbLjOXeAdzl7j/v8JaKiEjZFHPkcgBQ7+4r3f1dYD4wJWeZKcBN8fntwDgzszh9vrtvcvdVQH0sr9Uyzawf8DlARy4iIp1M9yKW2QVYk3jdABxYaBl3bzSzDcCAOP3xnPfuEp+3VuZRwP3u/kZrAe60004+dOjQ1hYTEZGEJUuWvOLuA0tRdjHJxfJMyz2XVmiZQtPzHTHllnkc8LOCQZnNAGYADBkyhLq6ukKLiohIHmb2QqnKLua0WAOwa+L1YGBtoWXMrDvQH1jfwntbLNPMBhBOnd1TKCh3v87dq929euDAkiReERFpp2KSyxPAcDMbZmY9gRqgNmeZWuCk+Hwq8ICHngK1QE3sTTYMGA4sLqLMY4C73X1jezdMREQqp9XTYrENZSZwL1AFzHH3ZWZ2AVDn7rXADcDNZlZPOGKpie9dZma3AsuBRuAMd98MkK/MxGprgIvS2kgRESmvVrsidwbV1dWe2+by3nvv0dDQwMaNOviRZr1792bw4MH06NGj0qGIVJyZLXH36lKUXUyDfqfU0NBAv379GDp0KKFXtGzt3J1XX32VhoYGhg0bVulwRLq0Ljv8y8aNGxkwYIASi2xhZgwYMEBHsyJl0GWTC6DEIh+ifUKkPLp0culMFixYwPLly1tfMGXTp08v+3ovvPDCsq5PRMqvy7a55Bp6TsFLZtpl9UVfTLW8BQsWMGnSJEaMGPGheY2NjXTvXpqP6mc/K3idaurcHXfnwgsv5Lvf/W7Z1ivSGXX0Oyvt76i22mqSSyX84he/YPbs2bz77rsceOCBXH311fTv35+zzjqLu+++mz59+nDXXXfx/PPPU1tby0MPPcQPfvAD7rjjDk455RQOPvhgHn30USZPnszUqVP52te+xrp16xg4cCBz585lyJAhTJs2jd69e7Ns2TJeeuklLr/8ciZNmsRhhx3GlVdeyejRowE45JBDuOaaaxg1atQHYhw7diyXXXYZ1dXVbLvttpxxxhncd9997LDDDlx44YWcffbZvPjii/z4xz9m8uTJ3Hjjjdx5551s2rSJVatWcfzxx3P++ecDcPnllzNnzhwgHBF94xvfYPXq1RxxxBF89rOf5bHHHmP06NG88847jB49mpEjRzJv3jy+9KUvsWbNGjZu3MhZZ53FjBkzANh2220/VFc777wzL730EqeddhorV64E4JprruHggw/OW99VVVXl+rili0jjh2ilv9izQKfFSuTZZ5/llltu4dFHH2Xp0qVUVVUxb9483nrrLQ466CCefvppDj/8cK6//noOPvhgJk+ezKWXXsrSpUv5xCc+AcDrr7/OQw89xL/9278xc+ZMTjzxRJ555hm++tWvcuaZZ25Z1+rVq3nooYe45557OO2009i4cSPTp0/nxhtvBODPf/4zmzZt+lBiyfXWW28xduxYlixZQr9+/fj3f/93fve733HnnXdy3nnnbVlu8eLFzJs3j6VLl3LbbbdRV1fHkiVLmDt3LosWLeLxxx/n+uuv56mnngJgxYoVnHjiiTz11FPMnTuXPn36sHTpUubNmwfAnDlzWLJkCXV1dcyePZtXX311Szy5dQVw5plnMmbMGJ5++mmefPJJRo4cWbC+RaQylFxK5P7772fJkiXsv//+jB49mvvvv5+VK1fSs2dPJk2aBMCnP/1pVq9eXbCMY489dsvzxx57jOOPPx6AE044gUceeWTLvK985St069aN4cOHs9tuu/Hcc89xzDHHcPfdd/Pee+8xZ84cpk2b1mrMPXv2ZOLEiQDss88+jBkzhh49erDPPvt8IM7x48czYMAA+vTpw9FHH80jjzzCI488wlFHHcU222zDtttuy9FHH83DDz8MwMc//nEOOuigguudPXs2++67LwcddBBr1qzhL3/5y5Z48tXVAw88wOmnnw5AVVUV/fv3L1jfIlIZOi1WIu7OSSedxA9/+MMPTL/sssu29FiqqqqisbGxYBnbbLNNwXnJXk+5PaDMjL59+zJ+/Hjuuusubr311i0De06YMIGXXnqJ6urqD7W39OjRY0tZ3bp1o1evXlueJ+PMt76WLsZtaTsefPBB7rvvPh577DH69u3L2LFjt3QVTsbTWl0Vqm8RqQwduZTIuHHjuP3223n55ZcBWL9+PS+8UHgA0n79+vHmm28WnH/wwQczf/58AObNm8ehhx66Zd5tt93G+++/z/PPP8/KlSvZc889gdDuceaZZ7L//vuz4447AnDvvfeydOnSDjXk/+53v2P9+vW88847LFiwgEMOOYTDDz+cBQsW8Pbbb/PWW29x5513cthhh+V9f48ePXjvvfcA2LBhAzvssAN9+/blueee4/HHH8/7nqRx48ZxzTXXALB582beeOONNte3iJSWkkuJjBgxgh/84Ad84QtfYNSoUYwfP56//e1vBZevqanh0ksvZb/99uP555//0PzZs2czd+5cRo0axc0338wVV1yxZd6ee+7JmDFjOOKII7j22mvp3bs3EE4lbbfddpx88smpbtuhhx7KCSecwOjRo/nyl79MdXU1n/rUp5g2bRoHHHAABx54INOnT2e//fbL+/4ZM2YwatQovvrVrzJx4kQaGxsZNWoU3//+91s8fdbkiiuu4Pe//z377LMPn/70p1m2bFmb61tESqvLji327LPPsvfee1coovKZNm0akyZNYurUqR+at3btWsaOHctzzz1Ht27p/I648cYbqaur4yc/+Ukq5VXC1rJvSPtkpbdYOboia2wxabOf//znfO973+Pyyy9PLbGIlFpnv7ZDmim5dHJN3Y1znXjiiZx44ompr2/atGlF9TwTka2bftKKiEjqunRy6QrtSZIu7RMi5dFlT4v17t2bV199VcPuyxZN93Np6k0nzbLSiC1dR5dNLoMHD6ahoYF169ZVOhTJkKY7UYpIaXXZ5NKjRw/dbVA6BfWQkq6oS7e5iIhIZSi5iIhI6pRcREQkdUUlFzObaGYrzKzezM7JM7+Xmd0S5y8ys6GJeefG6SvMbEJrZVowy8z+bGbPmtmZiIhIp9Jqg76ZVQFXAeOBBuAJM6t19+SN108BXnP33c2sBrgYONbMRgA1wEhgEHCfme0R31OozGnArsBe7v6+mX0kjQ0VEZHyKebI5QCg3t1Xuvu7wHxgSs4yU4Cb4vPbgXEWLi6ZAsx3903uvgqoj+W1VObpwAXu/j6Au7/c/s0TEZFKKCa57AKsSbxuiNPyLuPujcAGYEAL722pzE8QjnrqzOzXZja8uE0REZGsKCa55Lu8PXcMjULLtHU6QC9gYxwG+npgTt6gzGbEBFSnCyVFRLKlmOTSQGgDaTIYWFtoGTPrDvQH1rfw3pbKbADuiM/vBEblC8rdr3P3anevHjhwYBGbISIi5VJMcnkCGG5mw8ysJ6GBvjZnmVrgpPh8KvCAhxECa4Ga2JtsGDAcWNxKmQuAz8XnY4A/t2/TRESkUlrtLebujWY2E7gXqALmuPsyM7sAqHP3WuAG4GYzqyccsdTE9y4zs1uB5UAjcIa7bwbIV2Zc5UXAPDP7V+AfwPT0NldERMqhqLHF3H0hsDBn2nmJ5xuBYwq8dxYwq5gy4/TXAQ2WJCWnkYBFSkdX6IuISOqUXEREJHVKLiIikjolFxERSV2XvVmYZJtukCXStenIRUREUqfkIiIiqVNyERGR1Cm5iIhI6pRcREQkdUouIiKSOnVF3spoPC0RKQcduYiISOqUXEREJHVKLiIikjolFxERSZ2Si4iIpE7JRUREUqfkIiIiqVNyERGR1Cm5iIhI6nSFfhnpBlkisrUo6sjFzCaa2Qozqzezc/LM72Vmt8T5i8xsaGLeuXH6CjOb0FqZZnajma0ys6XxMbpjmygiIuXW6pGLmVUBVwHjgQbgCTOrdfflicVOAV5z993NrAa4GDjWzEYANcBIYBBwn5ntEd/TUpnfdvfbU9g+ERGpgGKOXA4A6t19pbu/C8wHpuQsMwW4KT6/HRhnZhanz3f3Te6+CqiP5RVTpoiIdFLFJJddgDWJ1w1xWt5l3L0R2AAMaOG9rZU5y8yeMbMfmVmvfEGZ2QwzqzOzunXr1hWxGSIiUi7FJBfLM82LXKat0wHOBfYC9gd2BL6TLyh3v87dq929euDAgfkWERGRCikmuTQAuyZeDwbWFlrGzLoD/YH1Lby3YJnu/jcPNgFzCafQRESkEykmuTwBDDezYWbWk9BAX5uzTC1wUnw+FXjA3T1Or4m9yYYBw4HFLZVpZh+Lfw34EvCnjmygiIiUX6u9xdy90cxmAvcCVcAcd19mZhcAde5eC9wA3Gxm9YQjlpr43mVmdiuwHGgEznD3zQD5yoyrnGdmAwmnzpYCp6W3uSIiUg5FXUTp7guBhTnTzks83wgcU+C9s4BZxZQZp3+umJhERCS7NPyLiIikTslFRERSp+QiIiKpU3IREZHUKbmIiEjqlFxERCR1Si4iIpI6JRcREUmdkouIiKROyUVERFKn5CIiIqlTchERkdQpuYiISOqUXEREJHVKLiIikjolFxERSZ2Si4iIpE7JRUREUqfkIiIiqVNyERGR1Cm5iIhI6opKLmY20cxWmFm9mZ2TZ34vM7slzl9kZkMT886N01eY2YQ2lHmlmf2jfZslIiKV1L21BcysCrgKGA80AE+YWa27L08sdgrwmrvvbmY1wMXAsWY2AqgBRgKDgPvMbI/4noJlmlk1sH0qWwgMPeeeDpex+qIvphCJiMjWoZgjlwOAendf6e7vAvOBKTnLTAFuis9vB8aZmcXp8919k7uvAupjeQXLjMnsUuDsjm2aiIhUSjHJZRdgTeJ1Q5yWdxl3bwQ2AANaeG9LZc4Eat39b8VtgoiIZE2rp8UAyzPNi1ym0PR8Sc3NbBBwDDC21aDMZgAzAIYMGdLa4iIiUkbFHLk0ALsmXg8G1hZaxsy6A/2B9S28t9D0/YDdgXozWw30NbP6fEG5+3XuXu3u1QMHDixiM0REpFyKSS5PAMPNbJiZ9SQ00NfmLFMLnBSfTwUecHeP02tib7JhwHBgcaEy3f0ed/+ouw9196HA2+6+e0c3UkREyqvV02Lu3mhmM4F7gSpgjrsvM7MLgDp3rwVuAG6ORxnrCcmCuNytwHKgETjD3TcD5Csz/c0TEZFKKKbNBXdfCCzMmXZe4vlGQltJvvfOAmYVU2aeZbYtJj4REckWXaEvIiKpU3IREZHUKbmIiEjqlFxERCR1Si4iIpI6JRcREUmdkouIiKROyUVERFKn5CIiIqlTchERkdQpuYiISOqUXEREJHVKLiIikjolFxERSZ2Si4iIpE7JRUREUqfkIiIiqVNyERGR1Cm5iIhI6pRcREQkdUouIiKSOiUXERFJXVHJxcwmmtkKM6s3s3PyzO9lZrfE+YvMbGhi3rlx+gozm9BamWZ2g5k9bWbPmNntZrZtxzZRRETKrdXkYmZVwFXAEcAI4DgzG5Gz2CnAa+6+O/Aj4OL43hFADTASmAhcbWZVrZT5r+6+r7uPAl4EZnZwG0VEpMyKOXI5AKh395Xu/i4wH5iSs8wU4Kb4/HZgnJlZnD7f3Te5+yqgPpZXsEx3fwMgvr8P4B3ZQBERKb9ikssuwJrE64Y4Le8y7t4IbAAGtPDeFss0s7nA34G9gCuLiFFERDKkmORieablHk0UWqat08MT95OBQcCzwLF5gzKbYWZ1Zla3bt26fIuIiEiFFJNcGoBdE68HA2sLLWNm3YH+wPoW3ttqme6+GbgF+HK+oNz9OnevdvfqgQMHFrEZIiJSLsUklyeA4WY2zMx6Ehroa3OWqQVOis+nAg+4u8fpNbE32TBgOLC4UJkW7A5b2lyOBJ7r2CaKiEi5dW9tAXdvNLOZwL1AFTDH3ZeZ2QVAnbvXAjcAN5tZPeGIpSa+d5mZ3QosBxqBM+IRCQXK7AbcZGbbEU6dPQ2cnu4mi4hIqbWaXADcfSGwMGfaeYnnG4FjCrx3FjCryDLfBw4pJiYREckuXaEvIiKpU3IREZHUKbmIiEjqlFxERCR1Si4iIpI6JRcREUmdkouIiKROyUVERFKn5CIiIqlTchERkdQpuYiISOqUXEREJHVKLiIikjolFxERSZ2Si4iIpE7JRUREUqfkIiIiqVNyERGR1Cm5iIhI6pRcREQkdUouIiKSOiUXERFJXVHJxcwmmtkKM6s3s3PyzO9lZrfE+YvMbGhi3rlx+gozm9BamWY2L07/k5nNMbMeHdtEEREpt1aTi5lVAVcBRwAjgOPMbETOYqcAr7n77sCPgIvje0cANcBIYCJwtZlVtVLmPGAvYB+gDzC9Q1soIiJlV8yRywFAvbuvdPd3gfnAlJxlpgA3xee3A+PMzOL0+e6+yd1XAfWxvIJluvtCj4DFwOCObaKIiJRbMcllF2BN4nVDnJZ3GXdvBDYAA1p4b6tlxtNhJwC/KSJGERHJkGKSi+WZ5kUu09bpSVcDf3D3h/MGZTbDzOrMrG7dunX5FhERkQopJrk0ALsmXg8G1hZaxsy6A/2B9S28t8Uyzex8YCDwzUJBuft17l7t7tUDBw4sYjNERKRcikkuTwDDzWyYmfUkNNDX5ixTC5wUn08FHohtJrVATexNNgwYTmhHKVimmU0HJgDHufv7Hds8ERGphO6tLeDujWY2E7gXqALmuPsyM7sAqHP3WuAG4GYzqyccsdTE9y4zs1uB5UAjcIa7bwbIV2Zc5bXAC8BjoU8Av3L3C1LbYhERKblWkwuEHlzAwpxp5yWebwSOKfDeWcCsYsqM04uKSUREsktX6IuISOqUXEREJHVKLiIikjolFxERSZ2Si4iIpE7JRUREUqfkIiIiqVNyERGR1Cm5iIhI6pRcREQkdUouIiKSOiUXERFJnZKLiIikTslFRERSp+QiIiKpU3IREZHUKbmIiEjqlFxERCR1Si4iIpI6JRcREUmdkouIiKROyUVERFJXVHIxs4lmtsLM6s3snDzze5nZLXH+IjMbmph3bpy+wswmtFammc2M09zMdurY5omISCW0mlzMrAq4CjgCGAEcZ2YjchY7BXjN3XcHfgRcHN87AqgBRgITgavNrKqVMh8FPg+80MFtExGRCinmyOUAoN7dV7r7u8B8YErOMlOAm+Lz24FxZmZx+nx33+Tuq4D6WF7BMt39KXdf3cHtEhGRCiomuewCrEm8bojT8i7j7o3ABmBAC+8tpkwREemkikkulmeaF7lMW6cXzcxmmFmdmdWtW7euLW8VEZESKya5NAC7Jl4PBtYWWsbMugP9gfUtvLeYMlvk7te5e7W7Vw8cOLAtbxURkRIrJrk8AQw3s2Fm1pPQQF+bs0wtcFJ8PhV4wN09Tq+JvcmGAcOBxUWWKSIinVSrySW2ocwE7gWeBW5192VmdoGZTY6L3QAMMLN64JvAOfG9y4BbgeXAb4Az3H1zoTIBzOxMM2sgHM08Y2Y/S29zRUSkHLoXs5C7LwQW5kw7L/F8I3BMgffOAmYVU2acPhuYXUxcIiKSTbpCX0REUqfkIiIiqVNyERGR1Cm5iIhI6pRcREQkdUouIiKSOiUXERFJnZKLiIikTslFRERSp+QiIiKpU3IREZHUKbmIiEjqlFxERCR1Si4iIpI6JRcREUmdkouIiKROyUVERFKn5CIiIqlTchERkdQpuYiISOqUXEREJHVKLiIikrqikouZTTSzFWZWb2bn5Jnfy8xuifMXmdnQxLxz4/QVZjahtTLNbFgs4y+xzJ4d20QRESm3VpOLmVUBVwFHACOA48xsRM5ipwCvufvuwI+Ai+N7RwA1wEhgInC1mVW1UubFwI/cfTjwWixbREQ6kWKOXA4A6t19pbu/C8wHpuQsMwW4KT6/HRhnZhanz3f3Te6+CqiP5eUtM77nc7EMYplfav/miYhIJRSTXHYB1iReN8RpeZdx90ZgAzCghfcWmj4AeD2WUWhdIiKScd2LWMbyTPMilyk0PV9Sa2n5DwdlNgOYEV/+w8xW5FuuDXYCXik00y7uYOmdJ4asxJH5GLISRxZiyEocWYghK3EUGcPH0womVzHJpQHYNfF6MLC2wDINZtYd6A+sb+W9+aa/AmxvZt3j0Uu+dQHg7tcB1xURf1HMrM7dq9Mqr7PGkJU4FEO24shCDFmJIwsxZCmOQoo5LfYEMDz24upJaKCvzVmmFjgpPp8KPODuHqfXxN5kw4DhwOJCZcb3/D6WQSzzrvZvnoiIVEKrRy7u3mhmM4F7gSpgjrsvM7MLgDp3rwVuAG42s3rCEUtNfO8yM7sVWA40Ame4+2aAfGXGVX4HmG9mPwCeimWLiEgnUsxpMdx9IbAwZ9p5iecbgWMKvHcWMKuYMuP0lYTeZOWW2im2DshCDJCNOBRDsyzEkYUYIBtxZCEGyE4ceVk4EyUiIpIeDf8iIiKpU3IREZHUKbmIiABxhBBJSVEN+iJSembWzd3fr3QcWVDOujCzj9J8Afff4jTzjDRIZ2G/aE8MatDvADPbEzgZeAZY5e6PVSCGEcCZwPPA/7n7b8odQ4wjC3VR8Rjawsz2JgzeasDP3H1DimXvDhwFLAH+5u7PplV2KZjZHsBhhKGj/tfdN5XjCz5+BrcCfwJ6Ab9192vjvIokmFLuF+WMQafF2ileFPqr+HIoMNfMvlrmGAYTBv18gXB90c/NbHo5Y4hxZKEuKh5DW5jZEMJFxn2AvYFfm9mBZtYjhbKHA/cQhvb4EnCFmR3Z0XJLxcw+AfwvsA8wCVhsZh9zdy/lqap4AfclwHXufhxwKfA9MzsboEKJpWT7RdljcHc92vEg3ELgF4nXhwGvAl8tYwyfIYxs0PT6AMIvsFO2wrqoeAxtjPcY4JeJ198G7gQOiq+tA2UfB/wkPt+ekGD+BEyu9HYXiPcM4PrE60uBR4Bd4utuJVz3ecCkxOvhhGGrZna1/aLcMejIpf1egS2/fnD3hwn/xBeY2ZgyxfBX4BUz2ysewi8m3P/mh2Y2uUwxQDbqIgsxtMVTQDczGwXg7k1fqJeZ2Y4e/4vb6R/AzrHc1919AfA94Jtmtm8H4y6FpcB7ZjYAwN2/DfwR+I2Z9fbStje8A5ze9MLd/0K4VcikeERVbqXcL8oag5JLO7l7HWGAzpsS0x4GrgRGlSmGF4G3gXOA3nHaIuBfgUPKEUNcZxbqouIxtNFr8XG4me0E4O7/DSwjfJ7t5u7/Cwwys58lJt8PPA5U4guzNX8FdgP+qWmCu58N1BHa0EomfnFuNrMHEtOWEBr2K9F7rGT7RbljUHJpBzPrBuDuRwK7mdkvE7M3Ap8sYwwzCac+fmrNt5feBAxpWqZMcZS9LprOx8c7m1b08yhGsv3A3V8FfkpoND3OzPaKsx4gfH7tXUdVfDqRsA/8NK7vH8CbQCZG0U3um+6+GrgQOMfMTjCz7eKs/wP6ljCGpv1mMvCWmS00s8PMbCLhtOq2pVp3IoYP/I+War8oIo6m/Sa1GNRbrAiJL9D3E9N6uPt78flvCOf31xF+fX3Dw9hpacbQk/B5bUpMS8ZwHdCD0OPlU8A58XRIqjJSFzsSfhhtubGcNd+moSwxtDHeLbHF1wahwdjMPgX8C2F73ib8Q5/l7kWNBm5m2xLaJN5Ilh/L3oEwft9fCUcBM4AZ7n5fSpvWZma2g7u/Fp93c/f3E/GOAf6DcFrmbULb0Ux3/3UK690VGAS85+5PJqZXefNguv8BbAMcBFzqYVDekok/Bj8PzCXsDsm66NB+0YYYBrn72pxpqcSg5NIKMxsJfINw07L5wCJ3fyvOS36pjifcSfPv7v5gmt0YzeyTwHcJH/J8Qpfj5/PEMJJwn5zX3H1R2l0pM1QXPyH8grrX3S9PzCtLDG2Md2/gVMI1ZTcAyzzc2jv5T/wx4KOEL7Vn3P3RYuKNdXEJ4QfFHHefl5i35boEMzs5LrPK3e9NfyuLE3sh3UXohHJ+Ms7E3z0IjeqfAv7o7vd39LOLv7xvBx4inGY7xd1/mZi/Zb+Jr7dz9zdKuc/EmH5LGC1+uLtvTuwPHdov2hDDnoRehf/s7r+P05rW3fR5tD8Gr0CPiM7yINys7AnCL6gphPPW5wO7ljGGnQn3wPky8FnCr5xrgE/nLNdnK6iLj8YYjiac3llE7FGUxQewF6GX1nRgNvA/wMDE/KYfd73bUfausS6mEo7OlgE7FvG+kvc2amHdHwceA+4ALsmZ171E6/wI8CRwcnw9Ln4mg3OW2x0YUo46AkYAj8b9+GbginyfUXv2izbEsBeh08S0AvOrOhqD2lxatjfworv/0sOh4E3A8cA/mVkvCL9MzewsM+tdohh2BV519zs8/Lq4FTiQ0JtlWIxhN2BmPF1UKlmpi5fd/VceGvDfA843s2+a2UExhr1KHENRLFwT8C3gZnf/mbufGWd9vWkZd/d4auQ0M+ufbJMpwt7AC+5+u4dTfi/T3GYxNMYw2sy+nnyTx2+Mcovn9F8HngOuAnYws++Z2fZmtouH+0YNN7PjzaxPG+uiJf2AH7v73HhK9yGgHmg6qrM4/Z+B7aC0dWRmfYAfErrN/4rQttHPzAY1LZPYL06gWD7AAAATjUlEQVRtx35RTAxGuA1KN3e/MU77hpl918w+a2Y7eTiS6lAMSi4tawA2mNm4+LqR0G2yhubeWK8Bj3q4p00prAb+bmanxNc7ACsIFwqOjtNeB+5x9/UligGyURcrCA2v95jZk4S6uQUYCEy20C61gXA6pVQxtCqeUngPuAyYY82Ntg8STk8l9SSc3tvQxi+154FGM/upmS0G/k64Gn8ioQs2hM/jT+3cjFRYcxvdZg9Xea8mXJx3IbA/odG+qZPBLsByd38nrS94D6eP74vP3/fmtq+mL/OPeDh9+F13L2ldxf3iHeBUd78mTq4nHDXl3g9rG8JoAW3dL4qJwQntb5jZFWa2gNCL8GOEI+FJcfHtOhRDKQ//OvuD0L33fOAXhCtW/0hoND8euJbyXNDUHTiRcPh8L6G/eT/Cl8gCSnQ6IYt1EeMYAhwJ3Na07YRD/AeJpzUqvM/sCZwFDMoz7wjgqvi8GvhcB/eLwwm3Av91YvrBhNOoO2eoLnZJTDs3foENIHyxLgYuKFM8Tad6HgL2I7QjPE045VvqU2H56qJp/z2ccLpwnzLFMDS+HkDoPHFtYplTgf9JY30auLKA2Gi10cwuIvyi2olwWug9M3sfeNPjp1FKHk4XzCMkkkHAOnd/Mx6lrvNEL6RSyUpdwJZre140s0MIF4z+lHB6rDfZGIj1LGAsUGVmv3L31YnG9b6Eo41q4JfA19qzgvh5NAJ/AP5gZp80swkeGutfAd5KZUs67ixgDIm6IAzRcx5wBeEapNsIF7ru7SUe/8xjrzBCW93RhDbM89y9oZTrjT60XxCur+lGGAvvMWAP4P9K2JEg+XnUunt9/D9KWg58zsz6ufubHVmZTosV4L6l18Ymd1/p7ovd/e9mdgThF/wDrZWRYiyb3f0Nd3/O3V81s6OAywlHEOVYf2bqInHu9yngUDNbSOiBdImHW2RXWh3hF/l2QI2Zbe/N3bZfACYQ2hy+4eEizzZLfvHEL6dXgOPN7GZCr6gr3f2lDmxDWuoIp++2A4610DV6PeF03XnufhGwitDduJwDa25DuBjwv9z9rrTbNArIt1+4h1N1rwNrgYvNrJQ/kJKfx1QzG+Dub7v727Clh+VsQntQhxILqCsyEK4h8dg9NL7e0vc9Z7k+hJ3yGXe/o5wx5sTxTWC1u/8q7V858Qtgg7cy5Eal6yK2rwwj/Npb6+5LSviLry1xDSMcUT1K+JX4PmHkgHMJpyEeA6a7+91FltfqvmlmfQmneHYBVnrKXVbbK6cuxgKbgSrgJndfHpdJJc5YBzu6e4OFEaHXec5Ivk3rMrMvxfllq6cW9ov/cve/x2VGufszlYghLnIDYRDPu1KplzTOrXXmBzCS0JZxEXB+Ecs3nbc1UjpPSxj6YgKwTRvfl1oMsbwBhF/BpwP9sloXhdaVZl20M3Yj9GhbGF8fSxxCHhgQpw0qNtZi9k3yDOqY9n6RYl28Eetix7Q/L8KIyrMJ14PVAh9vYdmqfM8rtF/sUMHPoymG7eO0/ml+Llv1aTEz+wihS+1dhL73k82sqcvih4ZmaPrV2JTVPX4SHYzhE4TznOcSznW2OORE02FziX5xVRF2uCOBo1uKpZJ10bSuZF10dN1piNWwBnjQzKYQBoucT+h+O93CIIxrm5Ztqaxi901vvlDyA/tFCfaNNilQF78k1MU/m1mflGN8ltDmdjZwv7u/kPv/C1tGS9hsZv3MbHfPc4Yiba3sFzPiUVclYzjVzPp6PNJL63PZqpMLYfvXEoaXfoLQNfJjwPUQ/nGbvrgSX6bbAz+2eG1HR8SyRwPfB+YRGhnHFfpSjTE0xlNX89P+B3X3l4GfE37NfA2YYGa7WriyOjeOLl0X7ZFIcr2A6wg3WToV+B1wt7ete3Rb983GND+PjiqiLt5Jcz0eOjgsBuYQBlz8XCLx9oh/k/VUS7yupdSKqIu3u2QM5Tgky+KDcJi4PeFq988nplcRGr4uSk6Lf7cnXJl+eIpx7Eg8BUS4r8UcwnUK/XOW656I4bfAZ1Ouj6ZtvIww3tEQQvvAm8AxW1NdpLAd3YAxnX3fzEJdtFZP8W81oU1nYHw9E7ibMBr2UMI1Hb3jvP6xng7rSnWRxRgqtpFZecQd7xFgRGLa3vEfu1tiB96BkOVT3ymb1hGfzwRuJFyvMAn4VmLeDvHLtGT/GIQ+9zPi85WECxe/QmJ4ma2lLgrE15c4dAjh4rfcxFeV87rdN7rKwr6ZlbpoIYbPE47wbiJcSDo8Tv86ocvxKmBcnLZdnHZoF62LisfwgfJLWXiWHzlfYt8jXBTYNMz25wi/2reL83sSzn2PLWE83RLPjyV0732VeNRAOJ/8K0r8K50wYOATwJ+B0wgXmz1M87hLW01dFIitLQ3Hye0oupE0a/tmJeuilfXvTbiA95D4+juEYXCaEsy+xDH4CEeDRwAHdsW6yEoMH1hHKQrN4iNfls6p4DMIg0L+ijAI4FGJef1JYYDEfDHkm084v74Z+GLThx+/UHcqVV3kzL8I+Gbi9U6J512qLtoRd3fgasKQO2e1sG81na7qB3wi6/tmVuqiDes24EeEQSmPp/ko7mziPXzyxdsV6yJLMXxgPeXYCSv9IIyMegbN5+qTvwyT/8QfI4yx88nc5UoZQ54dZCrxfudpxlBEXXxoXSROv3S1umhjzMl6mka4iPUOEkO4AD3i32Q7yO+BT2V538xKXbRh/aMIPRp7En4IXQJUJ+afC4zfGuoiKzHkjavcO2YlHsCnCfeI+CjN1xt86Es19x+WFM9JthZDzrJVpYihHXGU5nA5I3XRhnhL1nCchX0zK3VRxLq70Tye3Z2EWw30IRzBXAQcVI79Nwt1kaUYCsZWiR20XA8Sh8GERs8L446Y9yIumrN6ahdWZSGGrMSRhRg6EHuqDceqi3att6kOPkoYjXse8EVCQ/a1wH+T04jdVesiazHkjavSO2oJP/SehBsD7Uq4fmIqYSThi+M/8gf+iRM7bn/C/RY6vJNmIYasxJGFGDoQe6oNx6qLNq+zG+EGWytpvpp8Z8IRzF2EL9e+wN5dvS6yGEPB2Cq1k5bhg+9PuBDvfmANseGKcOh4KWE8nZ3itO6J9/yBlLJ6FmLIShxZiKGdcafecKy6aPf6f0boGt80TMkgQhfsBZS5g0el6yIrMbT06LJX6HsYyuAVwl0bnyKcq4VwL4emq3PPNrNe3nzV7p2EmwY90lViyEocWYihrcxsFOH6mu8QrqkZTWgjwd0vAf6T0ND+Ad7KbRBUF0Wtr2n0gX3N7Ggz283dpxMaqp+MdTKA0EX9O+7+SnvW087YyloXWY2hVeXM9uV40Jy9kzeSmkEYNmNsnLYzMJnmQ8dehPO3Y7pKDFmJIwsxtCPmkjQcqy7avO7JhDtV3hYfF8TplxCO4p4FpmwNdZGlGIp9dMkh981sMnAyoZHrKsKtVf+F0JVzJeFCwW95uPFU0/DxA5ted5UYshJHFmJoY7xNY6d9lHCq6kjgfwhdNy8n3IzrAs8Z0r3IslUXxa23N2F0hks93E7hM3Hdz7n7z+Pw8e+6+1/LOGx+ReoiazEUrVJZrVQPwq08HyZk9m8TRv3ch3CnwpMJ57mnJJYvxa+LiseQlTiyEEMbYi1pw7HqotV1Nv3Y7R3X/wDh3jcQ2hdOJ9wLpsvXRRZjaHPMlQ4g5Q9g31jR309M+zphGPfq+LpP/FuqL/SKx5CVOLIQQzvjTr3hWHXR6nqaEssEwk3oehBOi90AfCHOO4TQ5tK/EnVUrrrIegxFx1rpAFKu+O2BWwhDxg9K7LDfIJx+2J4SXyeQhRiyEkcWYigixqaY9iX04Notvr6QcEvY7QlHF/OBPVUXHa+LFtb/WeAvxIv7CA3SM4ClhO62K4FJW0NdZCWGjjw6dZtL07lWMzuU0MPmVcKQ5DcTzmn/t7v/LS47xEtw3joLMWQljizE0B6xHWQW4TQVwLPufp6ZXUK4ffBA4Bx3v6sNZaouil9n071GrgT+z91/ambdPNyzpifhCvPdgb+7+5NlbGMpe11kMYZ2q3R2SyG7HwksAU4F/kQ4lN6ekM2vBj62NcSQlTiyEEMb4+0dY2u60OwzhF+GJ8bXw4gDQ9LGUzGqizav/9+Bf4nPe8a/+1WinipdF1mJoSOPTn2dS7w96NcIV52+SbhF75Pu/jrhcHpnwj9zl44hK3FkIYZiJK6h6A28Sxg8cr84+3HChY3jANx9lbv/NT4v+tey6qJdVgPHmtneMbR9CW0MZamnLNRFFmJIS6dLLonKH0HovvkKYSTQU4GT3b3BzL5EGK/pK+7+bFeMIStxZCGGtkicrppAaO+oAn4MfMbMvhD/SZ8BtjWz/olTNkWVHf9u9XXRwjqr4t8Pffe4+y8Igy1eThgn63rgB+Wop0rURRZjSFWlD53a8yCcbngKGAycB/wDGB3nHUI4BTG6q8eQlTiyEEMb4y1Zw7HqosV17US4f3vTqZzkLQWSz/cijBS9d3xdllM+5ayLLMeQ2rZUOoB2VP7oWNF7xdd7Eg6dHyGMqfMn4MiuHkNW4shCDG2I1eLjJ8CpcVrTTcl6AnsQrnj+VNPyqov21UWBdQ4hjFx8M7Bzcp0trYMS316gEnWRxRjSfnSn89lE+Acea2ZfJpx/XEO4+9rThPu//7HEPUqyEENW4shCDEVpWr+Z/Z3wDwvhhmTvAiMJvZEW5i7fBqqLltf5opn9L+HmaBeZ2Xfc/eWmnmGJmJquQu/u7o3u/n5H191KXGWviyzGkLZO1+ZC+GetA04gjC10JuH+BP/j7ve6+x+h5JWfhRiyEkcWYmir1ZSm4Vh10QIzO5IwoOIawumeH5vZxzx0Oe4Wl2lKLNsDPzWzndKOowWrqWCHggzFkI5KHzq190FzV8VqwumGcVtjDFmJIwsx5MTTdA+UvKdUCFeB/5rQ1XMxifvSqy7Sq4vEOrqTGICTcMrwh8Acmk+RJW8v8HtKcKfEjNRFxWMoy35X6QA68gERhpheRBlHRs1aDFmJIwsxJGKpaMOx6uJDMexPOLVzL3Bmoo6+TOj99Euab8G7PWFMsdTvW5ORuqh4DOV6dPYr9LcBPuLuqyp1HjsLMWQljizEEOMYApxFuEbgW+7+UtN5/Tg/b2zJZVKIQXURyhlO+DKdSvjC/A/gWne/w8wOBL4CzHH3ZWbWg3CV/nx3f7Cj684TSxb2i4rHUC6dOrmIFGJmYwkNx/8g3Ezq5dx/0NyG40rFWmqVqgsz248wWOcsD0O6bEfo5HAZ4ehkAmHU49/G5XsSRvx9OY31F4hpLBXeL7IQQzl0xgZ9kRZ1gobjsqlkXbj7U0A98K/x9RvufidhePibCKcMmxKLufu7JU4sFd8vshBD2VT6vJweeqT5ICMNx1l4lLsuaD4TsjcwBugXX98DPLg11UVWYyjnQ0cu0mWY2f6Ef9idCMOUQ/jlXEfoufVjM+vtH7wv/ffd/eGKBFxClagLd3czO4rwBXou4Vf36e7+ReA1M3u8A5vUblnYL7IQQ9lVOrvpoUcaD0LPmt8DAwjDrPwO+HKcdyDhyvCR8XUPwlAaYysdd1eqC8KtBW4B9o2vxwOzgfHx9UPAgVtDXWQthorsh5UOQA89OvogjBr7Is3DZmwHHEW4odL1cd4XEsv3JPTkqnjsXaUuCKfCrgSeIHYjBvoQeoddvjXVRdZiqNRDvcWkSzCzB4BB7r5XYtowYBfgLQ+NywW7enYl5aqL5PvjleQ1hITSG/ipuz9lZl8kdDc+Hdjk7pvbu752xljx/SILMVSCkot0Ok3/hHGIjI8Q7pPyppndA2zj7mMrG2H5VLou4rUqoz10Nb6UkFzqCD3EFgAnAl9391+XMo4YS8X3iyzEkBVKLtIpxYbj7wMvA+uBh939GjO7k3DnwoMqGmAZVaou4kWPVwD/DziNcN3G5TGWlYS2hpUex1QrhyzsF1mIIQvUW0w6nXgxXg3hBlwTgbnA3mY23t2PAjbFX9RdXqXqwsx2JQzVchmwAvgi4fvkFcIdONe4+y/KnFgqvl9kIYasUHKRTiWebpgF7Ab0i5MfIfxCPALA3ce4+6LKRFg+laoLM+tDOFK5DBhESCZrCSNBLwBGAH3TXGcRMVV8v8hCDFmi5CKZZ/aB27n2JJx+eRT4f2a2n7u/Q+ilNMDM+lq8lW5XlIW6iOu4hHDTrzmE02L9CQMvXgR8xt3r015vrizURRZiyColF8m82EB6oJmd6u5PE6507g48DtxoZv9JuIPffHd/u9w9ksopK3Xh7hvc/T5gEtALmEIY0gXgr6VYZ54YKl4XWYghq9SgL5mXxYbjSsliXZhZX8KQ+n3c/Q9lXG/F6yILMWSVkotkWmw43kg4h30L8GfgNsINld4ETnL3tZWLsHw6Q12U61qNLNRFFmLIMp0Wk8zKYsNxpXSWuihTYql4XWQhhqzTkYtkmpn1J9zJ8GrCYH47AD9y92fNbIi7v1jRAMtIddEsC3WRhRiyTMlFOgUz2wP4OnAc8IK7H2DxvhcVDq3sVBfNslAXWYghi5RcpNOoVMNxFqkummWhLrIQQ9YouUin1NUG+esI1UWzLNRFFmLIAiUXERFJnXqLiYhI6pRcREQkdUouIiKSOiUXERFJnZKLiIikTslFRERSp+QiIiKp+//xnAlG637wUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_train.columns, clf_rf.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'entropy-importance'})\n",
    "importances.sort_values(by='entropy-importance')[:10].plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 712 ms, total: 2min 54s\n",
      "Wall time: 44.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=123, reg_alpha=0,\n",
       "                                     re...da=1, scale_pos_weight=1,\n",
       "                                     seed=None, silent=None, subsample=1,\n",
       "                                     verbosity=1),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'classifier__colsample_bytree': [0.5],\n",
       "                         'classifier__learning_rate': [0.1],\n",
       "                         'classifier__max_depth': [6],\n",
       "                         'classifier__n_estimators': [500],\n",
       "                         'classifier__subsample': [1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_XGB_nsm = XGBClassifier(random_state=123, n_jobs=-1)\n",
    "\n",
    "param_grid_XGB = {'classifier__colsample_bytree':[0.5],\n",
    "                  'classifier__n_estimators':[500],\n",
    "                  'classifier__max_depth':[6],\n",
    "                  'classifier__learning_rate':[0.1],\n",
    "                  'classifier__subsample':[1]\n",
    "                 } \n",
    "\n",
    "grid_XGB_nsm = GridSearchCV(clf_XGB_nsm, param_grid=param_grid_XGB, cv=5)\n",
    "\n",
    "grid_XGB_nsm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18904, 120)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6790626322471435\n",
      "0.6625524561836583\n",
      "F1 score for XGB model is  0.6564811199861309\n",
      "F1 score for XGB model is  0.637235384776018\n"
     ]
    }
   ],
   "source": [
    "train_pred_xgbnsm = grid_XGB_nsm.predict(X_train)\n",
    "test_pred_xgbnsm = grid_XGB_nsm.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_true=Y_train, y_pred = train_pred_logreg))\n",
    "\n",
    "print(accuracy_score(y_true=Y_train, y_pred=train_pred_xgbnsm))\n",
    "print(accuracy_score(y_true=Y_test, y_pred=test_pred_xgbnsm))\n",
    "\n",
    "\n",
    "f1_train_xgbnsm = f1_score(y_true=Y_train, y_pred=train_pred_xgbnsm,average='weighted')\n",
    "f1_test_xgbnsm = f1_score(y_true=Y_test, y_pred=test_pred_xgbnsm,average='weighted')\n",
    "\n",
    "print(\"F1 score for XGB model is \",f1_train_xgbnsm)\n",
    "print(\"F1 score for XGB model is \",f1_test_xgbnsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 56s, sys: 11.2 s, total: 21min 7s\n",
      "Wall time: 21min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=123, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [10, 100, 500], 'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_svm = SVC(random_state=123)\n",
    "\n",
    "param_grid_svm = {'C':[10,100,500],\n",
    "                  'kernel':['rbf']\n",
    "                 } \n",
    "\n",
    "grid_XGB_svm = GridSearchCV(clf_svm, param_grid=param_grid_svm, cv=5)\n",
    "\n",
    "grid_XGB_svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_XGB_svm.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671868387642827\n",
      "0.6289804986423105\n",
      "F1 score for SVM model is  0.648518829426713\n",
      "F1 score for SVM model is  0.5957247292792748\n"
     ]
    }
   ],
   "source": [
    "train_pred_svm = grid_XGB_svm.predict(X_train)\n",
    "test_pred_svm = grid_XGB_svm.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_true=Y_train, y_pred = train_pred_logreg))\n",
    "\n",
    "print(accuracy_score(y_true=Y_train, y_pred=train_pred_svm))\n",
    "print(accuracy_score(y_true=Y_test, y_pred=test_pred_svm))\n",
    "\n",
    "\n",
    "f1_train_svm = f1_score(y_true=Y_train, y_pred=train_pred_svm,average='weighted')\n",
    "f1_test_svm = f1_score(y_true=Y_test, y_pred=test_pred_svm,average='weighted')\n",
    "\n",
    "print(\"F1 score for SVM model is \",f1_train_svm)\n",
    "print(\"F1 score for SVM model is \",f1_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Pre-Processing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.read_csv(url8,na_values=[' '],index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Senti_blob</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270007</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>$INTC</td>\n",
       "      <td>-3.062194</td>\n",
       "      <td>1.223466</td>\n",
       "      <td>1.741714</td>\n",
       "      <td>2.279266</td>\n",
       "      <td>-1.323573</td>\n",
       "      <td>-0.274912</td>\n",
       "      <td>-4.504449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270008</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>$CTSH</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>-2.184408</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>-0.264743</td>\n",
       "      <td>-0.836282</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.826353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270009</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>$CB</td>\n",
       "      <td>0.401281</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.083411</td>\n",
       "      <td>-1.147041</td>\n",
       "      <td>-0.485223</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>1.012811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270010</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>$CTAS</td>\n",
       "      <td>-0.783521</td>\n",
       "      <td>1.192929</td>\n",
       "      <td>0.813831</td>\n",
       "      <td>-0.368166</td>\n",
       "      <td>-1.113656</td>\n",
       "      <td>-0.553581</td>\n",
       "      <td>-0.683803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270011</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>$intc</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.679032</td>\n",
       "      <td>0.354336</td>\n",
       "      <td>-1.799055</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>0.297111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id        date ticker       SF1       SF2       SF3       SF4  \\\n",
       "0  270007  2018-07-21  $INTC -3.062194  1.223466  1.741714  2.279266   \n",
       "1  270008  2018-05-10  $CTSH  0.816263 -2.184408  0.157975 -0.264743   \n",
       "2  270009  2018-01-10    $CB  0.401281  0.091604  0.083411 -1.147041   \n",
       "3  270010  2018-10-24  $CTAS -0.783521  1.192929  0.813831 -0.368166   \n",
       "4  270011  2018-07-27  $intc  0.796507  0.455341  0.679032  0.354336   \n",
       "\n",
       "        SF5       SF6       SF7  senti_0  senti_1  senti_2  senti_3  senti_4  \\\n",
       "0 -1.323573 -0.274912 -4.504449      0.0      0.0      1.0      0.0      1.0   \n",
       "1 -0.836282  0.046276  0.826353      NaN      NaN      NaN      NaN      NaN   \n",
       "2 -0.485223 -0.601060  1.012811      NaN      NaN      NaN      NaN      NaN   \n",
       "3 -1.113656 -0.553581 -0.683803      0.0      0.0      1.0      1.0      0.0   \n",
       "4 -1.799055  0.126153  0.297111      0.0      0.0      1.0      0.0      2.0   \n",
       "\n",
       "   word_count Senti_blob  senti_train tweeted_day_of_week tweet_month  \n",
       "0         5.0    neutral          2.0            Saturday        July  \n",
       "1         NaN        NaN          NaN            Thursday         May  \n",
       "2         NaN        NaN          NaN           Wednesday     January  \n",
       "3        15.0    neutral          2.0           Wednesday     October  \n",
       "4         8.0    neutral          2.0              Friday        July  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_final.isna().sum()\n",
    "test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Senti_blob</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270007</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>$INTC</td>\n",
       "      <td>-3.062194</td>\n",
       "      <td>1.223466</td>\n",
       "      <td>1.741714</td>\n",
       "      <td>2.279266</td>\n",
       "      <td>-1.323573</td>\n",
       "      <td>-0.274912</td>\n",
       "      <td>-4.504449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270008</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>$CTSH</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>-2.184408</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>-0.264743</td>\n",
       "      <td>-0.836282</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.826353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id        date ticker       SF1       SF2       SF3       SF4  \\\n",
       "0  270007  2018-07-21  $INTC -3.062194  1.223466  1.741714  2.279266   \n",
       "1  270008  2018-05-10  $CTSH  0.816263 -2.184408  0.157975 -0.264743   \n",
       "\n",
       "        SF5       SF6       SF7  senti_0  senti_1  senti_2  senti_3  senti_4  \\\n",
       "0 -1.323573 -0.274912 -4.504449      0.0      0.0      1.0      0.0      1.0   \n",
       "1 -0.836282  0.046276  0.826353      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   word_count Senti_blob  senti_train tweeted_day_of_week tweet_month  \n",
       "0         5.0    neutral          2.0            Saturday        July  \n",
       "1         NaN        NaN          NaN            Thursday         May  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final['date'] = pd.to_datetime(test_final['date']).dt.date\n",
    "\n",
    "test_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_final['alpha'] = grid_XGB_nsm.predict(test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>SF1</th>\n",
       "      <th>SF2</th>\n",
       "      <th>SF3</th>\n",
       "      <th>SF4</th>\n",
       "      <th>SF5</th>\n",
       "      <th>SF6</th>\n",
       "      <th>SF7</th>\n",
       "      <th>senti_0</th>\n",
       "      <th>senti_1</th>\n",
       "      <th>senti_2</th>\n",
       "      <th>senti_3</th>\n",
       "      <th>senti_4</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Senti_blob</th>\n",
       "      <th>senti_train</th>\n",
       "      <th>tweeted_day_of_week</th>\n",
       "      <th>tweet_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270007</td>\n",
       "      <td>2018-07-21</td>\n",
       "      <td>$INTC</td>\n",
       "      <td>-3.062194</td>\n",
       "      <td>1.223466</td>\n",
       "      <td>1.741714</td>\n",
       "      <td>2.279266</td>\n",
       "      <td>-1.323573</td>\n",
       "      <td>-0.274912</td>\n",
       "      <td>-4.504449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270008</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>$CTSH</td>\n",
       "      <td>0.816263</td>\n",
       "      <td>-2.184408</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>-0.264743</td>\n",
       "      <td>-0.836282</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>0.826353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>May</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270009</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>$CB</td>\n",
       "      <td>0.401281</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.083411</td>\n",
       "      <td>-1.147041</td>\n",
       "      <td>-0.485223</td>\n",
       "      <td>-0.601060</td>\n",
       "      <td>1.012811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270010</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>$CTAS</td>\n",
       "      <td>-0.783521</td>\n",
       "      <td>1.192929</td>\n",
       "      <td>0.813831</td>\n",
       "      <td>-0.368166</td>\n",
       "      <td>-1.113656</td>\n",
       "      <td>-0.553581</td>\n",
       "      <td>-0.683803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>October</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270011</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>$intc</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.455341</td>\n",
       "      <td>0.679032</td>\n",
       "      <td>0.354336</td>\n",
       "      <td>-1.799055</td>\n",
       "      <td>0.126153</td>\n",
       "      <td>0.297111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>July</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id        date ticker       SF1       SF2       SF3       SF4  \\\n",
       "0  270007  2018-07-21  $INTC -3.062194  1.223466  1.741714  2.279266   \n",
       "1  270008  2018-05-10  $CTSH  0.816263 -2.184408  0.157975 -0.264743   \n",
       "2  270009  2018-01-10    $CB  0.401281  0.091604  0.083411 -1.147041   \n",
       "3  270010  2018-10-24  $CTAS -0.783521  1.192929  0.813831 -0.368166   \n",
       "4  270011  2018-07-27  $intc  0.796507  0.455341  0.679032  0.354336   \n",
       "\n",
       "        SF5       SF6       SF7  senti_0  senti_1  senti_2  senti_3  senti_4  \\\n",
       "0 -1.323573 -0.274912 -4.504449      0.0      0.0      1.0      0.0      1.0   \n",
       "1 -0.836282  0.046276  0.826353      NaN      NaN      NaN      NaN      NaN   \n",
       "2 -0.485223 -0.601060  1.012811      NaN      NaN      NaN      NaN      NaN   \n",
       "3 -1.113656 -0.553581 -0.683803      0.0      0.0      1.0      1.0      0.0   \n",
       "4 -1.799055  0.126153  0.297111      0.0      0.0      1.0      0.0      2.0   \n",
       "\n",
       "   word_count Senti_blob  senti_train tweeted_day_of_week tweet_month  \n",
       "0         5.0    neutral          2.0            Saturday        July  \n",
       "1         NaN        NaN          NaN            Thursday         May  \n",
       "2         NaN        NaN          NaN           Wednesday     January  \n",
       "3        15.0    neutral          2.0           Wednesday     October  \n",
       "4         8.0    neutral          2.0              Friday        July  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents1 = pca.fit_transform(test_final[['SF1','SF2','SF3','SF4','SF5','SF6','SF7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf2 = pd.DataFrame(data = principalComponents1\n",
    "             , columns = ['pc1','pc2','pc3','pc4','pc5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_final.drop(['SF1','SF2','SF3','SF4','SF5','SF6','SF7'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.concat([principalDf2, test_final], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['alpha'] = grid_XGB_nsm.predict(test_final)\n",
    "test_final[['Id','alpha']].to_csv('sub_final4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
